{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a09110",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "* [Introduction](#1)\n",
    "* [Workspace Preparation](#2)\n",
    "* [Data Preparation](#3)\n",
    "* [Getting x_train, x_test, y_train, y_test](#4)\n",
    "* [MLFlow workspace preparation and Use](#5)\n",
    "* [Conclusions](#6)\n",
    "* [References](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f6d0b8",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "> Nota: Este Jupyter Notebook en la mayor medida esta en Ingles. Se encuentra en español las partes del contexto y habra comentarios con spanglish. ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-marks",
   "metadata": {},
   "source": [
    "### Escenario del Notebook\n",
    "\n",
    "- Una empresa activa en Big Data y Data Science desea contratar científicos de datos entre las personas que aprueben exitosamente algunos cursos impartidos por la empresa. Muchas personas se inscriben en su capacitación. La empresa quiere saber cuáles de estos candidatos realmente desean trabajar para la empresa después de la capacitación o si están buscando un nuevo empleo, ya que esto ayuda a reducir los costos y el tiempo, así como la calidad de la capacitación o la planificación de los cursos y la categorización de los candidatos. La información relacionada con la demografía, la educación y la experiencia está disponible a partir de la inscripción y matrícula de los candidatos.\n",
    "\n",
    "- Este conjunto de datos está diseñado para comprender los factores que llevan a una persona a dejar su trabajo actual, también para investigaciones de recursos humanos. Utilizando el modelo o modelos que utilicen las credenciales actuales, la demografía y los datos de experiencia, **se predecirá la probabilidad de que un candidato busque un nuevo empleo o trabaje para la empresa, además de interpretar los factores que afectan la decisión del empleado.** \n",
    "\n",
    "- Todos los datos se dividen en conjuntos de entrenamiento y prueba. \n",
    "\n",
    "- El objetivo no está incluido en la prueba, pero se cuenta con el archivo de datos de los valores objetivo de prueba para tareas relacionadas. \n",
    "\n",
    "- También se proporciona una muestra de envío correspondiente al identificador de inscrito en el conjunto de prueba con las columnas: enrollee_id, target.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30234859",
   "metadata": {},
   "source": [
    "# Workspace preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "subsequent-anthropology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#%config Completer.use_jedi=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "annoying-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, classification_report)\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c6131",
   "metadata": {},
   "source": [
    "# Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "strategic-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(Path(\"../data/aug_train.csv\"))\n",
    "targets = data[[\"target\"]]\n",
    "data.drop([\"enrollee_id\", \"target\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "worse-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = []\n",
    "numerical_features = []\n",
    "\n",
    "for column in data.columns:\n",
    "    dtype = str(data[column].dtype)\n",
    "    if dtype in [\"float64\", \"int64\"]:\n",
    "        numerical_features.append(column)\n",
    "    else:\n",
    "        categorical_features.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "computational-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "for categorical_feature in categorical_features:\n",
    "    data[categorical_feature].fillna('missing', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "atmospheric-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "for categorical_feature in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    data[categorical_feature] = le.fit_transform(data[categorical_feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cec0272",
   "metadata": {},
   "source": [
    "## Getting x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "liable-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data.values, \n",
    "                                                    targets.values.ravel(), \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=2021,\n",
    "                                                    stratify=targets.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "painful-diagnosis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13410, 12) (5748, 12)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "collect-clark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13410,) (5748,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd39bf36",
   "metadata": {},
   "source": [
    "# MLFlow workspace preparation and Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5288f83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_uri_from_aws = str(input(\"Cual es la URL de instancia de EC2\"))\n",
    "#\"http://3.226.165.98:5000/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "substantial-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(mlflow_uri_from_aws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "nervous-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_uri = mlflow.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "comprehensive-future",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://3.226.165.98:5000/'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff43cfd",
   "metadata": {},
   "source": [
    "## Part1: Checking MLflow Default Experiment and Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90c82d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment_id: 0\n",
      "Artifact Location: s3://mlflow-artifact-store-awscday/0\n",
      "Tags: {}\n",
      "Lifecycle_stage: active\n",
      "Creation timestamp: 1689034898116\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Case sensitive name\n",
    "experiment = mlflow.get_experiment_by_name(\"Default\")\n",
    "print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "print(\"Tags: {}\".format(experiment.tags))\n",
    "print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
    "print(\"Creation timestamp: {}\".format(experiment.creation_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "581ec770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from mlflow import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "run = MlflowClient().search_runs(\n",
    "    experiment_ids=\"2\",\n",
    "    filter_string=\"\",\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=1,\n",
    "    order_by=[\"metrics.accuracy DESC\"],\n",
    ")\n",
    "\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfef0341",
   "metadata": {},
   "source": [
    "## Part2: Understanding MLFlow Functions with scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "140cfcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01B3_MFlow_LR_train'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name_formlflow = str(input(\"Cual es el nombre de tu experimento ?:\"))\n",
    "\"01B3_MFlow_LR_train\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c0ad1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01B3_MFlow_LR_train\n"
     ]
    }
   ],
   "source": [
    "print(experiment_name_formlflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93e625b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 01B3_MFlow_LR_train\n",
      "Experiment_id: 22\n",
      "Artifact Location: s3://mlflow-artifact-store-awscday/22\n",
      "Tags: {}\n",
      "Lifecycle_stage: active\n"
     ]
    }
   ],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "# Create an experiment with a name that is unique and case sensitive.\n",
    "client = MlflowClient()\n",
    "\n",
    "#experiment_name_formlflow = \"01Basic_MFlow_LR_train\"\n",
    "# Create an experiment name, which must be unique and case sensitive\n",
    "experiment_id = client.create_experiment(\n",
    "    experiment_name_formlflow\n",
    ")\n",
    "\n",
    "# Fetch experiment metadata information\n",
    "experiment = client.get_experiment(experiment_id)\n",
    "print(\"Name: {}\".format(experiment.name))\n",
    "print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "print(\"Tags: {}\".format(experiment.tags))\n",
    "print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c3f430",
   "metadata": {},
   "source": [
    "### Experiment 1, Smaller Group of Parameters and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "black-costa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/mlflow_local/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(experiment_id=experiment_id):\n",
    "    class_weight = \"balanced\"\n",
    "    max_iter = 1000\n",
    "\n",
    "    logistic_regression = LogisticRegression(class_weight=class_weight, max_iter=max_iter)\n",
    "    logistic_regression.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = logistic_regression.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    mlflow.log_param(\"class_weight\", class_weight)\n",
    "    mlflow.log_param(\"max_iter\", max_iter)\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1\", f1)\n",
    "    mlflow.log_metric(\"auc\", auc) \n",
    "    \n",
    "    mlflow.sklearn.log_model(logistic_regression, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e977f7",
   "metadata": {},
   "source": [
    "#### Using nested=True in Experiment1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "556c4924",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(experiment_id=experiment_id,nested=True):\n",
    "    # tracking run parameters, ecosystem\n",
    "    mlflow.log_param(\"compute\", 'local')\n",
    "    mlflow.log_param(\"dataset\", 'kaggle-dataset')\n",
    "    mlflow.log_param(\"dataset_version\", '1.0')\n",
    "    mlflow.log_param(\"algo\", 'Logistic Regression')\n",
    "\n",
    "    class_weight = \"balanced\"\n",
    "    max_iter = 1000\n",
    "\n",
    "    logistic_regression = LogisticRegression(class_weight=class_weight, max_iter=max_iter)\n",
    "    logistic_regression.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = logistic_regression.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    mlflow.log_param(\"class_weight\", class_weight)\n",
    "    mlflow.log_param(\"max_iter\", max_iter)\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1\", f1)\n",
    "    mlflow.log_metric(\"auc\", auc) \n",
    "    \n",
    "    mlflow.sklearn.log_model(logistic_regression, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a10df5",
   "metadata": {},
   "source": [
    "### Experiment 2, Bigger Group of Parameters and Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f642594b",
   "metadata": {},
   "source": [
    "#### Adjusting metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aef4656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train dataset URL\n",
    "dataset_source_url=\"https://www.kaggle.com/datasets/arashnic/hr-analytics-job-change-of-data-scientists?resource=download&select=aug_train.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38efe47",
   "metadata": {},
   "source": [
    "#### Using MlflowClient() to create experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa8e25bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment with a name that is unique and case sensitive.\n",
    "client = MlflowClient()\n",
    "\n",
    "experiment_name_formlflow = \"02B3_MFlow_LR_train\"\n",
    "# Create an experiment name, which must be unique and case sensitive\n",
    "experiment_id = client.create_experiment(\n",
    "    experiment_name_formlflow\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff39e906",
   "metadata": {},
   "source": [
    "#### Making run over experiment with mlflow.start_run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc103b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(experiment_id=experiment_id):\n",
    "\n",
    "    # tracking run parameters, ecosystem\n",
    "    mlflow.log_param(\"compute\", 'local')\n",
    "    mlflow.log_param(\"dataset\", 'kaggle-dataset')\n",
    "    mlflow.log_param(\"dataset_version\", '1.0')\n",
    "    mlflow.log_param(\"dataset_path\", '../data/aug_train.csv\"')\n",
    "    mlflow.log_param(\"dataset_url\", dataset_source_url)\n",
    "    mlflow.log_param(\"algo\", 'Logistic Regression')\n",
    "\n",
    "    class_weight = \"balanced\"\n",
    "    max_iter = 1000\n",
    "\n",
    "    logistic_regression = LogisticRegression(class_weight=class_weight, max_iter=max_iter)\n",
    "    logistic_regression.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = logistic_regression.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    mlflow.log_param(\"class_weight\", class_weight)\n",
    "    mlflow.log_param(\"max_iter\", max_iter)\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1\", f1)\n",
    "    mlflow.log_metric(\"auc\", auc) \n",
    "    \n",
    "    mlflow.sklearn.log_model(logistic_regression, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3b1df05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 02B3_MFlow_LR_train\n",
      "Experiment_id: 23\n",
      "Artifact Location: s3://mlflow-artifact-store-awscday/23\n",
      "Tags: {}\n",
      "Lifecycle_stage: active\n",
      "Creation timestamp: 1689264796535\n"
     ]
    }
   ],
   "source": [
    "# Fetch experiment metadata information\n",
    "experiment = client.get_experiment(experiment_id)\n",
    "print(\"Name: {}\".format(experiment.name))\n",
    "print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "print(\"Tags: {}\".format(experiment.tags))\n",
    "print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
    "print(\"Creation timestamp: {}\".format(experiment.creation_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0033d2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "<Run: data=<RunData: metrics={'accuracy': 0.7352122477383438,\n",
      " 'auc': 0.7208662878564284,\n",
      " 'f1': 0.5658870507701085,\n",
      " 'precision': 0.4785335262904004,\n",
      " 'recall': 0.6922540125610607}, params={'algo': 'Logistic Regression',\n",
      " 'class_weight': 'balanced',\n",
      " 'compute': 'local',\n",
      " 'dataset': 'kaggle-dataset',\n",
      " 'dataset_path': '../data/aug_train.csv\"',\n",
      " 'dataset_url': 'https://www.kaggle.com/datasets/arashnic/hr-analytics-job-change-of-data-scientists?resource=download&select=aug_train.csv',\n",
      " 'dataset_version': '1.0',\n",
      " 'max_iter': '1000'}, tags={'mlflow.log-model.history': '[{\"run_id\": \"a44df8eaac0f4248a23b24b6bae2aa0f\", '\n",
      "                             '\"artifact_path\": \"model\", \"utc_time_created\": '\n",
      "                             '\"2023-07-13 16:13:25.602876\", \"flavors\": '\n",
      "                             '{\"python_function\": {\"model_path\": \"model.pkl\", '\n",
      "                             '\"predict_fn\": \"predict\", \"loader_module\": '\n",
      "                             '\"mlflow.sklearn\", \"python_version\": \"3.8.3\", '\n",
      "                             '\"env\": {\"conda\": \"conda.yaml\", \"virtualenv\": '\n",
      "                             '\"python_env.yaml\"}}, \"sklearn\": '\n",
      "                             '{\"pickled_model\": \"model.pkl\", '\n",
      "                             '\"sklearn_version\": \"0.22.1\", '\n",
      "                             '\"serialization_format\": \"cloudpickle\", \"code\": '\n",
      "                             'null}}, \"model_uuid\": '\n",
      "                             '\"d056b85273f34f308112253fa3295654\", '\n",
      "                             '\"mlflow_version\": \"2.4.2\"}]',\n",
      " 'mlflow.runName': 'caring-lamb-790',\n",
      " 'mlflow.source.name': '/opt/miniconda3/envs/mlflow_local/lib/python3.8/site-packages/ipykernel_launcher.py',\n",
      " 'mlflow.source.type': 'LOCAL',\n",
      " 'mlflow.user': 'camilamv'}>, info=<RunInfo: artifact_uri='s3://mlflow-artifact-store-awscday/23/a44df8eaac0f4248a23b24b6bae2aa0f/artifacts', end_time=1689264808269, experiment_id='23', lifecycle_stage='active', run_id='a44df8eaac0f4248a23b24b6bae2aa0f', run_name='caring-lamb-790', run_uuid='a44df8eaac0f4248a23b24b6bae2aa0f', start_time=1689264802665, status='FINISHED', user_id='camilamv'>, inputs=<RunInputs: dataset_inputs=[]>>\n"
     ]
    }
   ],
   "source": [
    "from mlflow.entities import ViewType\n",
    "\n",
    "run = MlflowClient().search_runs(\n",
    "    experiment_ids=\"23\",\n",
    "    filter_string=\"\",\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    order_by=[\"metrics.accuracy DESC\"],\n",
    ")\n",
    "\n",
    "print(len(run))\n",
    "print(run[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7666797c",
   "metadata": {},
   "source": [
    "#### Making rerun over experiment after using mlflow.set_experiment and adding aug_train data as artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "36f0125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name_formlflow=\"02B3_MFlow_LR_train\"\n",
    "#Set an experiment name, which must be unique and case sensitive\n",
    "experiment_id = mlflow.set_experiment(\n",
    "    experiment_name_formlflow\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ddfaa4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mlflow.entities.experiment.Experiment'> 23\n"
     ]
    }
   ],
   "source": [
    "print(type(experiment_id),experiment_id.experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "30059a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 02B3_MFlow_LR_train\n",
      "Experiment_id: 23\n",
      "Artifact Location: s3://mlflow-artifact-store-awscday/23\n",
      "Tags: {}\n",
      "Lifecycle_stage: active\n"
     ]
    }
   ],
   "source": [
    "experiment_id=experiment_id.experiment_id\n",
    "# Fetch experiment metadata information\n",
    "experiment = client.get_experiment(experiment_id)\n",
    "print(\"Name: {}\".format(experiment.name))\n",
    "print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "print(\"Tags: {}\".format(experiment.tags))\n",
    "print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5b090fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/65/1pl9_5wj56j1j9mtndbywpr80000gn/T/tmpwk860smm/aug_train.csv\n"
     ]
    }
   ],
   "source": [
    "# Re-run over experiment and logging train_data as artifact\n",
    "\n",
    "import os\n",
    "#Log data as artifact\n",
    "import tempfile\n",
    "\n",
    "data = pd.read_csv(Path(\"../data/aug_train.csv\"))\n",
    "targets = data[[\"target\"]]\n",
    "data.drop([\"enrollee_id\", \"target\"], inplace=True, axis=1)\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id):\n",
    "\n",
    "    # tracking run parameters, ecosystem\n",
    "    mlflow.log_param(\"compute\", 'local')\n",
    "    mlflow.log_param(\"dataset\", 'kaggle-dataset')\n",
    "    mlflow.log_param(\"dataset_version\", '1.0')\n",
    "    mlflow.log_param(\"dataset_path\", '../data/aug_train.csv\"')\n",
    "    mlflow.log_param(\"dataset_url\", dataset_source_url)\n",
    "    mlflow.log_param(\"algo\", 'Logistic Regression')\n",
    "\n",
    "    class_weight = \"balanced\"\n",
    "    max_iter = 1000\n",
    "\n",
    "    logistic_regression = LogisticRegression(class_weight=class_weight, max_iter=max_iter)\n",
    "    logistic_regression.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = logistic_regression.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    mlflow.log_param(\"class_weight\", class_weight)\n",
    "    mlflow.log_param(\"max_iter\", max_iter)\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1\", f1)\n",
    "    mlflow.log_metric(\"auc\", auc) \n",
    "    \n",
    "    mlflow.sklearn.log_model(logistic_regression, \"model\")\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmp:\n",
    "        path = os.path.join(tmp, 'aug_train.csv')\n",
    "        print(path)\n",
    "        data.to_csv(path)\n",
    "        mlflow.log_artifacts(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2249c2",
   "metadata": {},
   "source": [
    "### Experiment 3: Using Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e9ce5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.data\n",
    "import pandas as pd\n",
    "from mlflow.data.pandas_dataset import PandasDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d351bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name_formlflow=\"02B3_MFlow_LR_train\"\n",
    "#Set an experiment name, which must be unique and case sensitive\n",
    "experiment_id = mlflow.set_experiment(\n",
    "    experiment_name_formlflow\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aeee71a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mlflow.entities.experiment.Experiment'> 23\n"
     ]
    }
   ],
   "source": [
    "print(type(experiment_id),experiment_id.experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "787fbf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: 02B3_MFlow_LR_train\n",
      "Experiment_id: 23\n",
      "Artifact Location: s3://mlflow-artifact-store-awscday/23\n",
      "Tags: {}\n",
      "Lifecycle_stage: active\n"
     ]
    }
   ],
   "source": [
    "experiment_id=experiment_id.experiment_id\n",
    "# Fetch experiment metadata information\n",
    "experiment = client.get_experiment(experiment_id)\n",
    "print(\"Name: {}\".format(experiment.name))\n",
    "print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "print(\"Tags: {}\".format(experiment.tags))\n",
    "print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d4075f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/mlflow_local/lib/python3.8/site-packages/mlflow/data/pandas_dataset.py:116: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  return _infer_schema(self._df)\n"
     ]
    }
   ],
   "source": [
    "#Train dataset URL\n",
    "dataset_source_url=\"https://www.kaggle.com/datasets/arashnic/hr-analytics-job-change-of-data-scientists?resource=download&select=aug_train.csv\"\n",
    "\n",
    "#Using mlflow.data.pandas_dataset, to log_input dataset instead of artifact\n",
    "dataset = mlflow.data.pandas_dataset.from_pandas(data, source=dataset_source_url)\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id):\n",
    "    \n",
    "    # Log the dataset to the MLflow Run. Specify the \"training\" context to indicate that the\n",
    "    # dataset is used for model training\n",
    "    mlflow.log_input(dataset, context=\"training\")\n",
    "\n",
    "    # tracking run parameters, ecosystem\n",
    "    mlflow.log_param(\"compute\", 'local')\n",
    "    mlflow.log_param(\"dataset\", 'kaggle-dataset')\n",
    "    mlflow.log_param(\"dataset_version\", '1.0')\n",
    "    mlflow.log_param(\"dataset_url\", dataset_source_url)\n",
    "    mlflow.log_param(\"algo\", 'Logistic Regression')\n",
    "\n",
    "    class_weight = \"balanced\"\n",
    "    max_iter = 1000\n",
    "\n",
    "    logistic_regression = LogisticRegression(class_weight=class_weight, \n",
    "    max_iter=max_iter)\n",
    "    logistic_regression.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = logistic_regression.predict(x_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    mlflow.log_param(\"class_weight\", class_weight)\n",
    "    mlflow.log_param(\"max_iter\", max_iter)\n",
    "    \n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1\", f1)\n",
    "    mlflow.log_metric(\"auc\", auc) \n",
    "\n",
    "    mlflow.sklearn.log_model(logistic_regression, \"model\")\n",
    "\n",
    "    # Retrieve the run, including dataset information\n",
    "    run = mlflow.get_run(mlflow.last_active_run().info.run_id)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c775c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name: dataset\n",
      "Dataset digest: b5ad9a5d\n",
      "Dataset profile: {\"num_rows\": 19158, \"num_elements\": 229896}\n",
      "Dataset schema: {\"mlflow_colspec\": [{\"type\": \"string\", \"name\": \"city\"}, {\"type\": \"double\", \"name\": \"city_development_index\"}, {\"type\": \"string\", \"name\": \"gender\"}, {\"type\": \"string\", \"name\": \"relevent_experience\"}, {\"type\": \"string\", \"name\": \"enrolled_university\"}, {\"type\": \"string\", \"name\": \"education_level\"}, {\"type\": \"string\", \"name\": \"major_discipline\"}, {\"type\": \"string\", \"name\": \"experience\"}, {\"type\": \"string\", \"name\": \"company_size\"}, {\"type\": \"string\", \"name\": \"company_type\"}, {\"type\": \"string\", \"name\": \"last_new_job\"}, {\"type\": \"long\", \"name\": \"training_hours\"}]}\n"
     ]
    }
   ],
   "source": [
    "#Getting dataset information\n",
    "dataset_info = run.inputs.dataset_inputs[0].dataset\n",
    "print(f\"Dataset name: {dataset_info.name}\")\n",
    "print(f\"Dataset digest: {dataset_info.digest}\")\n",
    "print(f\"Dataset profile: {dataset_info.profile}\")\n",
    "print(f\"Dataset schema: {dataset_info.schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "225198b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d5927bf6e30d472595068813b30ffc80'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking last active run\n",
    "run = mlflow.last_active_run()\n",
    "run.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ef000217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset's source, which downloads the content from the source URL to the local\n",
    "# filesystem\n",
    "#dataset_source = mlflow.data.get_source(dataset_info)\n",
    "#data_loaded = dataset_source.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5282892d",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68471a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b85cdadb",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193826bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda0894d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f63ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e146013",
   "metadata": {},
   "source": [
    "# Other key functions and Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "2578bab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%% Experiments by the name: 02B_MFlow_LR_train are: 0\n",
      "%% Making loop over experiments list \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def assert_experiment_names_equal(experiments, expected_names):\n",
    "    actual_names = [e.name for e in experiments if e.name != \"Default\"]\n",
    "    assert actual_names == expected_names, (actual_names, expected_names)\n",
    "\n",
    "search_name='02B_MFlow_LR_train'\n",
    "# Search for experiments with full_name \n",
    "experiments = mlflow.search_experiments(filter_string=\"name = '02B_MFlow_LR_train'\")\n",
    "#assert_experiment_names_equal(experiments, [search_name])\n",
    "\n",
    "print(f'%% Experiments by the name: {search_name} are: {len(experiments)}')\n",
    "print(f'%% Making loop over experiments list \\n')\n",
    "for element in experiments:\n",
    "    print(\"Name: {}\".format(element.name))\n",
    "    print(\"Experiment_id: {}\".format(element.experiment_id))\n",
    "    print(\"Artifact Location: {}\".format(element.artifact_location))\n",
    "    print(\"Tags: {}\".format(element.tags))\n",
    "    print(\"Lifecycle_stage: {}\".format(element.lifecycle_stage))\n",
    "    print(\"Creation timestamp: {}\".format(element.creation_time))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "ddbe52d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The experiment is active.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Specify the name of the experiment you want to check\n",
    "experiment_name = \"02B2_MFlow_LR_train\"\n",
    "\n",
    "# Get the experiment by name\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "# Check if the experiment exists and if it is active\n",
    "if experiment is not None and experiment.lifecycle_stage == \"active\":\n",
    "    print(\"The experiment is active.\")\n",
    "else:\n",
    "    print(\"The experiment is either not found or not active.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8aae1abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Construct a Pandas DataFrame using iris flower data from a web URL\n",
    "# dataset_source_url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "# df = pd.read_csv(dataset_source_url)\n",
    "# # Construct an MLflow PandasDataset from the Pandas DataFrame, and specify the web URL\n",
    "# # as the source\n",
    "# dataset = mlflow.data.pandas_dataset.from_pandas(df, source=dataset_source_url)\n",
    "\n",
    "# with mlflow.start_run(experiment_id=experiment_id):\n",
    "#     # Log the dataset to the MLflow Run. Specify the \"training\" context to indicate that the\n",
    "#     # dataset is used for model training\n",
    "#     mlflow.log_input(dataset, context=\"training\")\n",
    "\n",
    "# # Retrieve the run, including dataset information\n",
    "# run = mlflow.get_run(mlflow.last_active_run().info.run_id)\n",
    "# dataset_info = run.inputs.dataset_inputs[0].dataset\n",
    "# print(f\"Dataset name: {dataset_info.name}\")\n",
    "# print(f\"Dataset digest: {dataset_info.digest}\")\n",
    "# print(f\"Dataset profile: {dataset_info.profile}\")\n",
    "# print(f\"Dataset schema: {dataset_info.schema}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f8d92b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.datasets import load_diabetes\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# mlflow.autolog()\n",
    "\n",
    "# db = load_diabetes()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
    "\n",
    "# # Create and train models.\n",
    "# rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
    "# rf.fit(X_train, y_train)\n",
    "\n",
    "# # Use the model to make predictions on the test dataset.\n",
    "# predictions = rf.predict(X_test)\n",
    "# autolog_run = mlflow.last_active_run()\n",
    "\n",
    "# mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "ddc1c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client = mlflow.MlflowClient()\n",
    "#data = client.get_run(mlflow.active_run().info.run_id).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b55c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_name_formlflow=\"01B3_MFlow_LR_train\"\n",
    "# #Set an experiment name, which must be unique and case sensitive\n",
    "# experiment_id = mlflow.set_experiment(\n",
    "#     experiment_name_formlflow\n",
    "# )\n",
    "\n",
    "# print(type(experiment_id),experiment_id.experiment_id)\n",
    "\n",
    "# from mlflow import MlflowClient\n",
    "\n",
    "# # Create an experiment with a name that is unique and case sensitive.\n",
    "# client = MlflowClient()\n",
    "\n",
    "# experiment_id=experiment_id.experiment_id\n",
    "# # Fetch experiment metadata information\n",
    "# experiment = client.get_experiment(experiment_id)\n",
    "# print(\"Name: {}\".format(experiment.name))\n",
    "# print(\"Experiment_id: {}\".format(experiment.experiment_id))\n",
    "# print(\"Artifact Location: {}\".format(experiment.artifact_location))\n",
    "# print(\"Tags: {}\".format(experiment.tags))\n",
    "# print(\"Lifecycle_stage: {}\".format(experiment.lifecycle_stage))\n",
    "\n",
    "\n",
    "# import json\n",
    "# import plotly.express as px\n",
    "# import mlflow\n",
    "# import requests\n",
    "    \n",
    "# ### prepare sample files to log\n",
    "# # test data\n",
    "# df = px.data.iris()\n",
    "\n",
    "# # sample CSV file\n",
    "# df.to_csv(\"1_data_sample.csv\")\n",
    "\n",
    "# # sample pandas HTML file\n",
    "# df.to_html(\"2_data_sample.html\")\n",
    "\n",
    "# # sample image\n",
    "# r = requests.get(\"https://upload.wikimedia.org/wikipedia/en/7/7d/Lenna_%28test_image%29.png\")\n",
    "# with open(\"3_image_sample.png\", 'wb') as f:\n",
    "#     f.write(r.content)\n",
    "    \n",
    "# # sample gif\n",
    "# r = requests.get(\"https://media1.giphy.com/media/bU3YVJAAXckCI/giphy.gif\")\n",
    "# with open(\"4_gif_sample.gif\", 'wb') as f:\n",
    "#     f.write(r.content)\n",
    "\n",
    "# # sample plotly plot - HTML\n",
    "# fig = px.scatter(df, x=\"sepal_width\", y=\"sepal_length\", color=\"species\", marginal_y=\"rug\", marginal_x=\"histogram\")\n",
    "# fig.write_html(\"5_plot_sample.html\")\n",
    "\n",
    "# # sample geojson\n",
    "# with open(\"6_map_sample.geojson\", \"w+\") as f:\n",
    "#     data = requests.get(\"https://gist.githubusercontent.com/wavded/1200773/raw/e122cf709898c09758aecfef349964a8d73a83f3/sample.json\").json()\n",
    "#     f.write(json.dumps(data))\n",
    "    \n",
    "# ### log files to mlflow experiment\n",
    "# with mlflow.start_run(experiment_id=experiment_id, run_name=\"file_display\") as run:\n",
    "    \n",
    "#     mlflow.log_param(\"parameter\",\"test\")\n",
    "#     mlflow.log_metric(\"the_answer\",42.0)\n",
    "    \n",
    "#     mlflow.log_artifact(\"./1_data_sample.csv\")\n",
    "#     mlflow.log_artifact(\"./2_data_sample.html\")\n",
    "#     mlflow.log_artifact(\"./3_image_sample.png\")\n",
    "#     mlflow.log_artifact(\"./4_gif_sample.gif\")\n",
    "#     mlflow.log_artifact(\"./5_plot_sample.html\")\n",
    "#     mlflow.log_artifact(\"./6_map_sample.geojson\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
